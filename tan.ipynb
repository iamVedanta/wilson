{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "328df255-91ba-4aec-a88a-8a86f0a7c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('wilson.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e03703a6-8ae7-4367-a82b-bc8c32ee686b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ceruloplasmin Level</th>\n",
       "      <th>Copper in Blood Serum</th>\n",
       "      <th>Free Copper in Blood Serum</th>\n",
       "      <th>Copper in Urine</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Total Bilirubin</th>\n",
       "      <th>...</th>\n",
       "      <th>Neurological Symptoms Score</th>\n",
       "      <th>Psychiatric Symptoms</th>\n",
       "      <th>Cognitive Function Score</th>\n",
       "      <th>Family History</th>\n",
       "      <th>ATB7B Gene Mutation</th>\n",
       "      <th>Region</th>\n",
       "      <th>Socioeconomic Status</th>\n",
       "      <th>Alcohol Use</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Is_Wilson_Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daniel Perry</td>\n",
       "      <td>14</td>\n",
       "      <td>Female</td>\n",
       "      <td>9.341193</td>\n",
       "      <td>229.035586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.987111</td>\n",
       "      <td>73.711588</td>\n",
       "      <td>72.047328</td>\n",
       "      <td>1.312437</td>\n",
       "      <td>...</td>\n",
       "      <td>5.078054</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>West</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>25.219815</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lauren Luna</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>9.149010</td>\n",
       "      <td>200.239637</td>\n",
       "      <td>16.153480</td>\n",
       "      <td>104.192937</td>\n",
       "      <td>25.896181</td>\n",
       "      <td>67.512312</td>\n",
       "      <td>0.221304</td>\n",
       "      <td>...</td>\n",
       "      <td>6.188963</td>\n",
       "      <td>0</td>\n",
       "      <td>96.844013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>South</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>33.516525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andrew Lewis</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>9.768630</td>\n",
       "      <td>267.343650</td>\n",
       "      <td>14.373756</td>\n",
       "      <td>153.177037</td>\n",
       "      <td>45.918204</td>\n",
       "      <td>76.687723</td>\n",
       "      <td>3.533976</td>\n",
       "      <td>...</td>\n",
       "      <td>4.432626</td>\n",
       "      <td>1</td>\n",
       "      <td>69.162053</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>West</td>\n",
       "      <td>High</td>\n",
       "      <td>True</td>\n",
       "      <td>26.233051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trevor Villegas</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>11.915923</td>\n",
       "      <td>221.104453</td>\n",
       "      <td>4.326112</td>\n",
       "      <td>159.542682</td>\n",
       "      <td>53.625145</td>\n",
       "      <td>103.375310</td>\n",
       "      <td>1.549835</td>\n",
       "      <td>...</td>\n",
       "      <td>3.529333</td>\n",
       "      <td>1</td>\n",
       "      <td>77.317382</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>West</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>38.991556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Mills</td>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>9.500291</td>\n",
       "      <td>230.140212</td>\n",
       "      <td>23.433224</td>\n",
       "      <td>124.989992</td>\n",
       "      <td>68.076335</td>\n",
       "      <td>82.279210</td>\n",
       "      <td>3.895870</td>\n",
       "      <td>...</td>\n",
       "      <td>4.764693</td>\n",
       "      <td>0</td>\n",
       "      <td>70.502837</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>East</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "      <td>32.787552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  Age     Sex  Ceruloplasmin Level  Copper in Blood Serum  \\\n",
       "0     Daniel Perry   14  Female             9.341193             229.035586   \n",
       "1      Lauren Luna   21  Female             9.149010             200.239637   \n",
       "2     Andrew Lewis   31    Male             9.768630             267.343650   \n",
       "3  Trevor Villegas   19    Male            11.915923             221.104453   \n",
       "4       John Mills   30  Female             9.500291             230.140212   \n",
       "\n",
       "   Free Copper in Blood Serum  Copper in Urine        ALT         AST  \\\n",
       "0                         NaN       144.987111  73.711588   72.047328   \n",
       "1                   16.153480       104.192937  25.896181   67.512312   \n",
       "2                   14.373756       153.177037  45.918204   76.687723   \n",
       "3                    4.326112       159.542682  53.625145  103.375310   \n",
       "4                   23.433224       124.989992  68.076335   82.279210   \n",
       "\n",
       "   Total Bilirubin  ...  Neurological Symptoms Score  Psychiatric Symptoms  \\\n",
       "0         1.312437  ...                     5.078054                     1   \n",
       "1         0.221304  ...                     6.188963                     0   \n",
       "2         3.533976  ...                     4.432626                     1   \n",
       "3         1.549835  ...                     3.529333                     1   \n",
       "4         3.895870  ...                     4.764693                     0   \n",
       "\n",
       "   Cognitive Function Score  Family History  ATB7B Gene Mutation  Region  \\\n",
       "0                       NaN               1                    1    West   \n",
       "1                 96.844013               1                    1   South   \n",
       "2                 69.162053               1                    1    West   \n",
       "3                 77.317382               1                    1    West   \n",
       "4                 70.502837               1                    1    East   \n",
       "\n",
       "   Socioeconomic Status  Alcohol Use        BMI  Is_Wilson_Disease  \n",
       "0                   Low        False  25.219815                  1  \n",
       "1                Medium        False  33.516525                  1  \n",
       "2                  High         True  26.233051                  1  \n",
       "3                  High        False  38.991556                  1  \n",
       "4                   Low         True  32.787552                  1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7be77723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name             Age  Sex     Ceruloplasmin Level  Copper in Blood Serum  Free Copper in Blood Serum  Copper in Urine  ALT        AST        Total Bilirubin  Albumin   Alkaline Phosphatase (ALP)  Prothrombin Time / INR  Gamma-Glutamyl Transferase (GGT)  Kayser-Fleischer Rings  Neurological Symptoms Score  Psychiatric Symptoms  Cognitive Function Score  Family History  ATB7B Gene Mutation  Region  Socioeconomic Status  Alcohol Use  BMI        Is_Wilson_Disease\n",
       "Aaron Anderson   7    Male    10.028943            199.599203             15.084071                   125.556245       87.114235  63.201289  2.669895         3.985740  162.193053                  1.226835                107.012158                        1                       6.905720                     0                     73.024507                 1               1                    South   Low                   True         38.305110  1                    1\n",
       "Melinda Smith    59   Female  21.210917            119.297377             19.888753                   82.705187        15.076687  32.817774  0.529692         4.412025  77.964356                   1.370632                74.127384                         0                       3.207777                     0                     80.971152                 0               0                    East    High                  False        23.606713  0                    1\n",
       "Melanie Tyler    68   Male    23.366158            41.107062              20.437578                   51.479078        26.541919  36.426521  1.315085         4.975531  153.788924                  1.140266                74.785466                         0                       0.743901                     1                     89.130665                 0               0                    South   High                  False        30.987738  0                    1\n",
       "Melanie Weaver   52   Male    24.068339            77.011712              15.026963                   73.106171        31.885488  32.759898  1.260023         3.922647  188.187085                  1.273513                63.627400                         0                       2.233132                     0                     88.172341                 0               0                    North   High                  True         37.852820  0                    1\n",
       "Melanie Wheeler  59   Male    22.309776            57.472302              14.083597                   47.491971        35.003749  38.871427  1.931518         5.312212  64.235500                   1.228211                36.583164                         0                       1.904206                     1                     85.485268                 0               0                    West    Medium                False        30.235123  0                    1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ..\n",
       "Gary Hayes       48   Female  16.886259            70.611534              23.187612                   63.646688        26.932481  22.687283  0.928516         4.320586  129.661708                  1.099378                77.977114                         0                       3.239681                     1                     86.689404                 1               0                    East    Low                   False        32.175422  0                    1\n",
       "Gary Henry       18   Female  10.691483            265.983709             16.471804                   156.441785       76.709352  46.587780  1.425228         4.169733  117.468934                  1.038071                121.594540                        0                       6.025992                     0                     84.380505                 0               1                    North   Low                   False        32.417876  1                    1\n",
       "Gary Hernandez   67   Female  21.619438            75.567876              16.336939                   48.271874        21.563191  44.394696  1.824346         4.875054  110.124285                  1.196020                39.689406                         0                       1.706564                     1                     86.100189                 1               0                    East    Medium                False        29.460421  0                    1\n",
       "Gary Howard      58   Male    25.755936            74.739160              12.097449                   74.792853        44.888689  13.678252  1.418542         5.134662  122.589173                  1.148675                73.996677                         0                       1.296190                     1                     85.491821                 0               0                    East    High                  True         28.244485  0                    1\n",
       "Zoe Perry        46   Male    33.289274            65.657226              11.286416                   69.082603        58.855569  53.151494  1.752088         3.859871  77.336213                   1.161740                65.110029                         0                       3.457729                     0                     86.437279                 0               0                    West    High                  True         38.811890  0                    1\n",
       "Name: count, Length: 15237, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79fd1818-5f5d-49ac-8a3c-a5b6dcdacf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Is_Wilson_Disease\n",
       "0    10166\n",
       "1     5071\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "# Retain only unique rows and remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# # Display the updated DataFrame with unique rows\n",
    "# print(df_unique)\n",
    "\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df['Is_Wilson_Disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0281de55-2cc3-41c9-bf99-5f914fc2dfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                                 object\n",
       "Age                                   int64\n",
       "Sex                                  object\n",
       "Ceruloplasmin Level                 float64\n",
       "Copper in Blood Serum               float64\n",
       "Free Copper in Blood Serum          float64\n",
       "Copper in Urine                     float64\n",
       "ALT                                 float64\n",
       "AST                                 float64\n",
       "Total Bilirubin                     float64\n",
       "Albumin                             float64\n",
       "Alkaline Phosphatase (ALP)          float64\n",
       "Prothrombin Time / INR              float64\n",
       "Gamma-Glutamyl Transferase (GGT)    float64\n",
       "Kayser-Fleischer Rings                int64\n",
       "Neurological Symptoms Score         float64\n",
       "Psychiatric Symptoms                  int64\n",
       "Cognitive Function Score            float64\n",
       "Family History                        int64\n",
       "ATB7B Gene Mutation                   int64\n",
       "Region                               object\n",
       "Socioeconomic Status                 object\n",
       "Alcohol Use                            bool\n",
       "BMI                                 float64\n",
       "Is_Wilson_Disease                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6a9929c-42b4-4680-943d-1a56c354d8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     1\n",
       "3     1\n",
       "8     1\n",
       "9     1\n",
       "12    1\n",
       "Name: Is_Wilson_Disease, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Is_Wilson_Disease']\n",
    "X = df.drop('Is_Wilson_Disease', axis=1)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1219b900-9fb6-4489-8752-272338e01bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                                0\n",
       "Age                                 0\n",
       "Sex                                 0\n",
       "Ceruloplasmin Level                 0\n",
       "Copper in Blood Serum               0\n",
       "Free Copper in Blood Serum          0\n",
       "Copper in Urine                     0\n",
       "ALT                                 0\n",
       "AST                                 0\n",
       "Total Bilirubin                     0\n",
       "Albumin                             0\n",
       "Alkaline Phosphatase (ALP)          0\n",
       "Prothrombin Time / INR              0\n",
       "Gamma-Glutamyl Transferase (GGT)    0\n",
       "Kayser-Fleischer Rings              0\n",
       "Neurological Symptoms Score         0\n",
       "Psychiatric Symptoms                0\n",
       "Cognitive Function Score            0\n",
       "Family History                      0\n",
       "ATB7B Gene Mutation                 0\n",
       "Region                              0\n",
       "Socioeconomic Status                0\n",
       "Alcohol Use                         0\n",
       "BMI                                 0\n",
       "Is_Wilson_Disease                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc77609",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleImputer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load your dataset\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# # Import necessary libraries\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# # Load your dataset\n",
    "# df = pd.read_csv('wilson.csv')\n",
    "\n",
    "# # Display a sample of the data\n",
    "# print(df.head())\n",
    "\n",
    "# # Separate numeric and non-numeric columns\n",
    "# numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "# non_numeric_columns = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# # Handle missing values by replacing NaN with the column mean for numeric columns\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# df_numeric_imputed = pd.DataFrame(imputer.fit_transform(df[numeric_columns]), columns=numeric_columns)\n",
    "\n",
    "# # Impute categorical columns with the most frequent value\n",
    "# categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "# df_non_numeric_imputed = pd.DataFrame(categorical_imputer.fit_transform(df[non_numeric_columns]), columns=non_numeric_columns)\n",
    "\n",
    "# # Combine imputed numeric and non-numeric columns back together\n",
    "# df_imputed = pd.concat([df_numeric_imputed, df_non_numeric_imputed], axis=1)\n",
    "\n",
    "# # Encoding categorical variables\n",
    "# label_encoder = LabelEncoder()\n",
    "# for col in non_numeric_columns:\n",
    "#     df_imputed[col] = label_encoder.fit_transform(df_imputed[col])\n",
    "\n",
    "# # Feature and target variables\n",
    "# X = df_imputed.drop('Is_Wilson_Disease', axis=1)  # Drop the target column\n",
    "# y = df_imputed['Is_Wilson_Disease']\n",
    "\n",
    "# # Handle class imbalance using SMOTE (Oversampling the minority class)\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# # Split the data into training and testing sets (80% training, 20% testing)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Scaling the data (using StandardScaler or MinMaxScaler)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Train a classifier (Random Forest as an example)\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Predictions\n",
    "# y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# # Evaluation Metrics\n",
    "# print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba7c059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725bd129-3db4-4676-9d34-8c01458818a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Replace only NaN values with the column mean\n",
    "# for column in df.columns:\n",
    "#     if df[column].isna().any():  # Check for NaN values\n",
    "#         mean_value = df[column].mean()  # Calculate mean (ignores NaN by default)\n",
    "#         df[column] = df[column].apply(lambda x: mean_value if pd.isna(x) else x)  # Replace NaN with mean\n",
    "\n",
    "# # Display the updated DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e855007-db05-42e2-9299-b3dbc8f37935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c9f0425-8c43-41ce-813f-53cf7ea955b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (12189, 24)\n",
      "Shape of test data: (3048, 24)\n",
      "Sample of preprocessed data:\n",
      "        Age  Ceruloplasmin Level  Copper in Blood Serum  \\\n",
      "14337  53.0            23.130145              77.212533   \n",
      "14165  50.0            20.675983              91.650489   \n",
      "15153  64.0            22.406904              91.921748   \n",
      "4077   17.0            14.696171             209.625215   \n",
      "15027  56.0            26.959718              86.067131   \n",
      "\n",
      "       Free Copper in Blood Serum  Copper in Urine        ALT        AST  \\\n",
      "14337                   10.073625        61.866509  39.950712  11.344724   \n",
      "14165                   15.167466        77.902952  30.276498  42.965971   \n",
      "15153                   24.255867        89.020918  43.246906  46.569345   \n",
      "4077                    17.666259       143.206727  32.160087  63.137885   \n",
      "15027                    6.718958        66.578159  41.916943  20.020646   \n",
      "\n",
      "       Total Bilirubin   Albumin  Alkaline Phosphatase (ALP)  ...  \\\n",
      "14337         1.489387  4.759601                  137.165634  ...   \n",
      "14165         1.609075  3.189123                  113.531778  ...   \n",
      "15153         1.529976  4.486015                  164.718243  ...   \n",
      "4077          2.806968  4.512962                  169.246612  ...   \n",
      "15027         1.950282  4.568529                  127.514079  ...   \n",
      "\n",
      "       Psychiatric Symptoms  Cognitive Function Score  Family History  \\\n",
      "14337                   0.0                 84.764059             0.0   \n",
      "14165                   0.0                 91.364498             1.0   \n",
      "15153                   1.0                 85.108953             1.0   \n",
      "4077                    1.0                 80.365613             1.0   \n",
      "15027                   0.0                 82.346196             0.0   \n",
      "\n",
      "       ATB7B Gene Mutation        BMI   Name  Sex  Region  \\\n",
      "14337                  0.0  19.126147  12693    0       2   \n",
      "14165                  0.0  25.418766    913    1       0   \n",
      "15153                  0.0  35.852601   7541    0       3   \n",
      "4077                   0.0  24.241953   2175    0       2   \n",
      "15027                  0.0  39.629778  12935    0       1   \n",
      "\n",
      "       Socioeconomic Status  Alcohol Use  \n",
      "14337                     1            0  \n",
      "14165                     2            1  \n",
      "15153                     2            1  \n",
      "4077                      0            1  \n",
      "15027                     0            0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#DATA PREPROCESSING\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Separate numeric and non-numeric columns\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "non_numeric_columns = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Handle missing values by replacing NaN with the column mean for numeric columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_numeric_imputed = pd.DataFrame(imputer.fit_transform(df[numeric_columns]), columns=numeric_columns)\n",
    "\n",
    "# Combine numeric and non-numeric columns back together\n",
    "df_imputed = pd.concat([df_numeric_imputed, df[non_numeric_columns].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Encoding categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for col in non_numeric_columns:\n",
    "    df_imputed[col] = label_encoder.fit_transform(df_imputed[col])\n",
    "\n",
    "# Feature and target variables\n",
    "X = df_imputed.drop('Is_Wilson_Disease', axis=1)  # Drop the target column\n",
    "y = df_imputed['Is_Wilson_Disease']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display a summary of processed data\n",
    "print(\"Shape of training data:\", X_train.shape)\n",
    "print(\"Shape of test data:\", X_test.shape)\n",
    "print(\"Sample of preprocessed data:\")\n",
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dc3a6b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# # Apply PCA to reduce dimensionality\n",
    "# pca = PCA(n_components=100)  # Choose a suitable number of components\n",
    "# X_reduced = pca.fit_transform(X.toarray())  # Convert sparse matrix to dense for PCA\n",
    "\n",
    "# # Train the model with reduced features\n",
    "# model = LogisticRegression(solver='lbfgs')\n",
    "# model.fit(X_reduced, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from scipy.sparse import csr_matrix\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming df is your DataFrame\n",
    "# y = df['Is_Wilson_Disease']\n",
    "# X = df.drop('Is_Wilson_Disease', axis=1)\n",
    "\n",
    "# # One-hot encode the data (you can choose to encode only categorical columns)\n",
    "# encoder = OneHotEncoder(sparse=True)  # Use sparse=True to avoid dense matrix\n",
    "# X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# # Convert the target variable to numpy array\n",
    "# y = y.to_numpy()  # Convert target to numpy array if it's not already\n",
    "\n",
    "# # Initialize StratifiedShuffleSplit with desired number of splits and test size\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.33, random_state=42)\n",
    "\n",
    "# for train_index, test_index in sss.split(X_encoded, y):\n",
    "#     X_train, X_test = X_encoded[train_index], X_encoded[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# # Train the logistic regression model (use the sparse matrix)\n",
    "# model = LogisticRegression(solver='lbfgs')\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Print classification report\n",
    "# print(f\"Logistic Regression Hold-out Test Accuracy: {model.score(X_test, y_test)}\")\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Is_Wilson_Disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc3abcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Hold-out Test Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      2007\n",
      "         1.0       1.00      1.00      1.00      1041\n",
      "\n",
      "    accuracy                           1.00      3048\n",
      "   macro avg       1.00      1.00      1.00      3048\n",
      "weighted avg       1.00      1.00      1.00      3048\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2007    0]\n",
      " [   0 1041]]\n"
     ]
    }
   ],
   "source": [
    "# Pre-pruning for Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree with pre-pruning\n",
    "decision_tree = DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5)\n",
    "\n",
    "# Train the model\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "print(\"Decision Tree Hold-out Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a2c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdc9a906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Hold-out Test Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      2007\n",
      "         1.0       1.00      1.00      1.00      1041\n",
      "\n",
      "    accuracy                           1.00      3048\n",
      "   macro avg       1.00      1.00      1.00      3048\n",
      "weighted avg       1.00      1.00      1.00      3048\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2007    0]\n",
      " [   0 1041]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "print(\"Logistic Regression Hold-out Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "097004e1-f4ce-414f-aabd-868f5e77365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Cross-Validation Accuracy: 0.9998 Â± 0.0001\n",
      "Hold-out Test Accuracy: 0.99975\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      8037\n",
      "         1.0       1.00      1.00      1.00      3963\n",
      "\n",
      "    accuracy                           1.00     12000\n",
      "   macro avg       1.00      1.00      1.00     12000\n",
      "weighted avg       1.00      1.00      1.00     12000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8037    0]\n",
      " [   3 3960]]\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Cross-Validation Accuracy: 1.0000 Â± 0.0000\n",
      "Hold-out Test Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      8037\n",
      "         1.0       1.00      1.00      1.00      3963\n",
      "\n",
      "    accuracy                           1.00     12000\n",
      "   macro avg       1.00      1.00      1.00     12000\n",
      "weighted avg       1.00      1.00      1.00     12000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8037    0]\n",
      " [   0 3963]]\n",
      "==================================================\n",
      "Model: SVM\n",
      "Cross-Validation Accuracy: 1.0000 Â± 0.0000\n",
      "Hold-out Test Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      8037\n",
      "         1.0       1.00      1.00      1.00      3963\n",
      "\n",
      "    accuracy                           1.00     12000\n",
      "   macro avg       1.00      1.00      1.00     12000\n",
      "weighted avg       1.00      1.00      1.00     12000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8037    0]\n",
      " [   0 3963]]\n",
      "==================================================\n",
      "Model: Decision Tree\n",
      "Cross-Validation Accuracy: 1.0000 Â± 0.0000\n",
      "Hold-out Test Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      8037\n",
      "         1.0       1.00      1.00      1.00      3963\n",
      "\n",
      "    accuracy                           1.00     12000\n",
      "   macro avg       1.00      1.00      1.00     12000\n",
      "weighted avg       1.00      1.00      1.00     12000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8037    0]\n",
      " [   0 3963]]\n",
      "==================================================\n",
      "Model: KNN\n",
      "Cross-Validation Accuracy: 0.9937 Â± 0.0012\n",
      "Hold-out Test Accuracy: 0.99425\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      8037\n",
      "         1.0       1.00      0.98      0.99      3963\n",
      "\n",
      "    accuracy                           0.99     12000\n",
      "   macro avg       1.00      0.99      0.99     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8037    0]\n",
      " [  69 3894]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('wilson.csv')\n",
    "\n",
    "# Separate numeric and non-numeric columns\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "non_numeric_columns = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_numeric_imputed = pd.DataFrame(imputer.fit_transform(df[numeric_columns]), columns=numeric_columns)\n",
    "\n",
    "# Combine imputed numeric and original non-numeric columns\n",
    "df_imputed = pd.concat([df_numeric_imputed, df[non_numeric_columns].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for col in non_numeric_columns:\n",
    "    df_imputed[col] = label_encoder.fit_transform(df_imputed[col])\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler = MinMaxScaler()  # Rescales data to [0, 1]\n",
    "normalized_data = scaler.fit_transform(df_imputed)\n",
    "df_normalized = pd.DataFrame(normalized_data, columns=df_imputed.columns)\n",
    "\n",
    "# Feature and target variables\n",
    "X = df_normalized.drop('Is_Wilson_Disease', axis=1)\n",
    "y = df_normalized['Is_Wilson_Disease']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=500),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5),  # Limit depth\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    # Cross-validation scores\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    print(f\"Cross-Validation Accuracy: {scores.mean():.4f} Â± {scores.std():.4f}\")\n",
    "    \n",
    "    # Train and evaluate on the hold-out test seta\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Hold-out Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "311c13b1-a102-438b-9ef6-d7e5208ba0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Mean Squared Error: 0.0160\n",
      "==================================================\n",
      "Model: Gradient Boosting\n",
      "Mean Squared Error: 0.0000\n",
      "==================================================\n",
      "Model: SVR\n",
      "Mean Squared Error: 0.0833\n",
      "==================================================\n",
      "Model: Decision Tree\n",
      "Mean Squared Error: 0.0000\n",
      "==================================================\n",
      "Model: KNN Regressor\n",
      "Mean Squared Error: 0.0214\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Regression Models (Predicting continuous values)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('wilson.csv')\n",
    "\n",
    "# Separate numeric and non-numeric columns\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "non_numeric_columns = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Handle missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_numeric_imputed = pd.DataFrame(imputer.fit_transform(df[numeric_columns]), columns=numeric_columns)\n",
    "\n",
    "# Combine imputed numeric and original non-numeric columns\n",
    "df_imputed = pd.concat([df_numeric_imputed, df[non_numeric_columns].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in non_numeric_columns:\n",
    "    df_imputed[col] = label_encoder.fit_transform(df_imputed[col])\n",
    "\n",
    "# Feature and target variables\n",
    "X = df_imputed.drop('Is_Wilson_Disease', axis=1)\n",
    "y = df_imputed['Is_Wilson_Disease']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the regression models\n",
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'SVR': SVR(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'KNN Regressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Train and evaluate each regression model\n",
    "for model_name, model in regression_models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model's performance\n",
    "    mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
